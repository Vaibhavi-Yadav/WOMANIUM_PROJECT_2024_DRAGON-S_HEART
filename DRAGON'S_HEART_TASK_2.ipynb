{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$TASK-2 $$ \n",
    "To familiarize yourself with the basic workflow in Quantum Machine Learning, work through the tutorial on Variational Classifier. Implement and present the usual steps in this workflow and explain in your own words the purpose of each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we installed pennylane on our local IDE(VsCode) for better understanding of Variational Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pennylane --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this program, we saw how to use PennyLane to implement variational quantum classifiers - quantum circuits that can be trained from labelled data to classify new data samples. We used two examples for this which are inspired by two of the first papers that proposed variational circuits as supervised machine learning models: Farhi and Neven (2018) as well as Schuld et al. (2018)."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 1: Fitting the parity function \n",
    "\n",
    "It shows that a variational circuit can be optimized to emulate the parity function   \n",
    "                    ![image.png](attachment:image.png)\n",
    "                    \n",
    "It demonstrates how to encode binary inputs into the initial state of the variational circuit, which is simply a computational basis state (basis encoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Imports**\n",
    "\n",
    "First, we need to import the necessary libraries. We'll use PennyLane for quantum operations, PennyLane's version of NumPy for numerical operations, and an optimizer for training the quantum circuit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer                                                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Quantum Device Initialization**\n",
    "\n",
    "We define the quantum device that will be used to simulate our quantum circuit. Here, we use the default.qubit device provided by PennyLane, which is a classical simulator of a quantum computer.\n",
    "\n",
    "**•\tdefault.qubit :** This is a statevector simulator that simulates the behavior of a quantum computer.\n",
    "\n",
    "**•\twires=4 :** We specify that our quantum circuit will use 4 qubits (wires).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Circuit Layer Definition**\n",
    "\n",
    "Next, we define a function to create a single layer of our quantum circuit. A layer consists of arbitrary rotations on each qubit followed by a series of CNOT gates that entangle neighboring qubits.\n",
    "\n",
    "**• qml.Rot :** This gate applies an arbitrary rotation on a qubit, parameterized by three angles.\n",
    "\n",
    "**• CNOT gates :** These gates are used to entangle qubits. Entanglement is essential for creating quantum correlations between qubits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(layer_weights):\n",
    "    for wire in range(4):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)\n",
    "\n",
    "    for wires in ([0, 1], [1, 2], [2, 3], [3, 0]):\n",
    "        qml.CNOT(wires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. State Preparation**\n",
    "\n",
    "The input data (bitstrings) needs to be encoded into the quantum circuit. The state preparation function does this by setting the quantum state to correspond to the bitstring.\n",
    "\n",
    "**•\tqml.BasisState :** This function prepares the qubits in a specific computational basis state based on the input bitstring x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_preparation(x):\n",
    "    qml.BasisState(x, wires=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Variational Quantum Circuit**\n",
    "\n",
    "We define the full variational quantum circuit by combining the state preparation and the repeated layers of rotations and CNOT gates.\n",
    "\n",
    "**•\t@qml.qnode(dev) :** This decorator converts the circuit function into a quantum node (QNode) that can be executed on the quantum device dev.\n",
    "\n",
    "**•\tqml.expval(qml.PauliZ(0)) :** This measures the expectation value of the Pauli-Z operator on the first qubit, which serves as the output of the quantum circuit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    state_preparation(x)\n",
    "\n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Variational Classifier**\n",
    "\n",
    "We then define the full variational classifier model, which includes the quantum circuit and a classical bias term.\n",
    "\n",
    "**•\tBias :** The bias term is added to the output of the quantum circuit to form the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Cost Function**\n",
    "\n",
    "A)  The cost function is a crucial part of training machine learning models. Here, we use the square loss function, which         measures the difference between the predicted and true labels.\n",
    "\n",
    "**•\tnp.mean :** Calculates the mean of the squared differences between the predicted and true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    # We use a call to qml.math.stack to allow subtracting the arrays directly\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B)  Additionally, we define the accuracy metric to evaluate how well the classifier is performing.\n",
    "\n",
    "**•\tAccuracy :** This function calculates the proportion of predictions that match the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)  Finally, we define the cost function that will be minimized during training.\n",
    "\n",
    "**•\tX and Y :** These represent the input data and corresponding labels, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Optimization**\n",
    "\n",
    "Now, let's load and preprocess the data, initialize the model parameters, and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"ENTER TASK_2_Example1_TRAIN dataset HERE\", dtype=int)\n",
    "X = np.array(data[:, :-1])\n",
    "Y = np.array(data[:, -1])\n",
    "Y = Y * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
    "\n",
    "for x,y in zip(X, Y):\n",
    "    print(f\"x = {x}, y = {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the variables randomly (but fix a seed for reproducibility). Remember that one of the variables is used as a bias, while the rest is fed into the gates of the variational circuit.\n",
    "\n",
    "**•\tnum_layers = 2 :** The number of layers in the quantum circuit.\n",
    "\n",
    "**•\tweights_init :** Randomly initialized weights for the circuit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(\"Weights:\", weights_init)\n",
    "print(\"Bias: \", bias_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an optimizer instance and choose a batch size…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = NesterovMomentumOptimizer(0.5)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Results**\n",
    "\n",
    "We run the optimizer to train our model. We track the accuracy - the share of correctly classified data samples. For this we compute the outputs of the variational classifier and turn them into predictions in  {\n",
    "−\n",
    "1\n",
    ",\n",
    "1\n",
    "}\n",
    "  by taking the sign of the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(100):\n",
    "\n",
    "    # Update the weights by one optimizer step, using only a limited batch of data\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "\n",
    "    current_cost = cost(weights, bias, X, Y)\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Testing on Unseen Data**\n",
    "\n",
    "To evaluate the generalization of the model, we test it on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"ENTER TASK_2_Example1_TEST dataset HERE\", dtype=int)\n",
    "X_test = np.array(data[:, :-1])\n",
    "Y_test = np.array(data[:, -1])\n",
    "Y_test = Y_test * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
    "\n",
    "predictions_test = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
    "\n",
    "for x,y,p in zip(X_test, Y_test, predictions_test):\n",
    "    print(f\"x = {x}, y = {y}, pred={p}\")\n",
    "\n",
    "acc_test = accuracy(Y_test, predictions_test)\n",
    "print(\"Accuracy on unseen data:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "The variational quantum classifier was successfully implemented and trained to recognize the parity function using a small synthetic dataset. This example demonstrates the core steps in building and training a quantum machine learning model using PennyLane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 2 : IRIS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Overview**\n",
    "\n",
    "We want to classify data points from the Iris dataset using a quantum variational classifier. The data points are represented as real-valued vectors, which will be encoded into quantum states. Specifically, we will use a quantum circuit with 2 qubits to represent 2-dimensional input vectors (with some additional latent dimensions).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Quantum State Preparation**\n",
    "\n",
    "First, we need to prepare the quantum states based on the input vectors. The state preparation routine takes a vector x and converts it into a set of rotation angles that can be used to prepare the quantum state.\n",
    "\n",
    "•\tThe **get_angles** function converts the input vector x into a set of angles.\n",
    "\n",
    "•\tThese angles are computed based on the magnitude of the elements of the vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(x):\n",
    "    beta0 = 2 * np.arcsin(np.sqrt(x[1] ** 2) / np.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n",
    "    beta1 = 2 * np.arcsin(np.sqrt(x[3] ** 2) / np.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n",
    "    beta2 = 2 * np.arcsin(np.linalg.norm(x[2:]) / np.linalg.norm(x))\n",
    "\n",
    "    return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State Preparation Circuit :**\n",
    "\n",
    "•\tThe **state_preparation** function prepares the quantum state using the angles a computed from the input vector x.\n",
    "\n",
    "•\tIt uses a series of rotations (qml.RY) and controlled NOT gates (qml.CNOT) to prepare the desired quantum state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_preparation(a):\n",
    "    qml.RY(a[0], wires=0)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[1], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[2], wires=1)\n",
    "\n",
    "    qml.PauliX(wires=0)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[3], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[4], wires=1)\n",
    "    qml.PauliX(wires=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the State Preparation :**\n",
    "\n",
    "•\tWe test the state preparation by feeding it a sample input vector x.\n",
    "\n",
    "•\tThe output shows that the quantum state has been prepared correctly based on the input vector.\n",
    "\n",
    "•   The method computed the correct angles to prepare the desired state!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.53896774, 0.79503606, 0.27826503, 0.0], requires_grad=False)\n",
    "ang = get_angles(x)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def test(angles):\n",
    "    state_preparation(angles)\n",
    "\n",
    "    return qml.state()\n",
    "\n",
    "\n",
    "state = test(ang)\n",
    "\n",
    "print(\"x               : \", np.round(x, 6))\n",
    "print(\"angles          : \", np.round(ang, 6))\n",
    "print(\"amplitude vector: \", np.round(np.real(state), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with only 2 qubits now, we need to update the layer function. In addition, we redefine the cost function to pass the full batch of data to the state preparation of the circuit simultaneously, a technique similar to NumPy broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(layer_weights):\n",
    "    for wire in range(2):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    # Transpose the batch of input data in order to make the indexing\n",
    "    # in state_preparation work\n",
    "    predictions = variational_classifier(weights, bias, X.T)\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Data Preprocessing**\n",
    "\n",
    "The Iris dataset is loaded, and the input vectors are padded and normalized. This preprocessing is crucial for ensuring that the data can be encoded into quantum states.\n",
    "\n",
    "•\tThe data points are padded to size 4 to match the size of the state vector in the quantum device.\n",
    "\n",
    "•\tThe padded data points are then normalized.\n",
    "\n",
    "•\tFinally, the get_angles function is used to convert the normalized data into rotation angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"Enter your TEST_2_Example2_IRIS DATASET HERE\")\n",
    "X = data[:, 0:2]\n",
    "print(f\"First X sample (original)  : {X[0]}\")\n",
    "\n",
    "# pad the vectors to size 2^2=4 with constant values\n",
    "padding = np.ones((len(X), 2)) * 0.1\n",
    "X_pad = np.c_[X, padding]\n",
    "print(f\"First X sample (padded)    : {X_pad[0]}\")\n",
    "\n",
    "# normalize each input\n",
    "normalization = np.sqrt(np.sum(X_pad**2, -1))\n",
    "X_norm = (X_pad.T / normalization).T\n",
    "print(f\"First X sample (normalized): {X_norm[0]}\")\n",
    "\n",
    "# the angles for state preparation are the features\n",
    "features = np.array([get_angles(x) for x in X_norm], requires_grad=False)\n",
    "print(f\"First features sample      : {features[0]}\")\n",
    "\n",
    "Y = data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing Preprocessing :**\n",
    "\n",
    "•\tThe original, normalized, and feature-transformed data are visualized to see how the preprocessing affects the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0][Y == 1], X[:, 1][Y == 1], c=\"b\", marker=\"o\", ec=\"k\")\n",
    "plt.scatter(X[:, 0][Y == -1], X[:, 1][Y == -1], c=\"r\", marker=\"o\", ec=\"k\")\n",
    "plt.title(\"Original data\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "dim1 = 0\n",
    "dim2 = 1\n",
    "plt.scatter(X_norm[:, dim1][Y == 1], X_norm[:, dim2][Y == 1], c=\"b\", marker=\"o\", ec=\"k\")\n",
    "plt.scatter(X_norm[:, dim1][Y == -1], X_norm[:, dim2][Y == -1], c=\"r\", marker=\"o\", ec=\"k\")\n",
    "plt.title(f\"Padded and normalised data (dims {dim1} and {dim2})\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "dim1 = 0\n",
    "dim2 = 3\n",
    "plt.scatter(features[:, dim1][Y == 1], features[:, dim2][Y == 1], c=\"b\", marker=\"o\", ec=\"k\")\n",
    "plt.scatter(features[:, dim1][Y == -1], features[:, dim2][Y == -1], c=\"r\", marker=\"o\", ec=\"k\")\n",
    "plt.title(f\"Feature vectors (dims {dim1} and {dim2})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Model Training**\n",
    "\n",
    "We split the data into training and validation sets and initialize the quantum variational classifier.\n",
    "\n",
    "•\tThe dataset is split into training and validation sets to monitor generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "num_data = len(Y)\n",
    "num_train = int(0.75 * num_data)\n",
    "index = np.random.permutation(range(num_data))\n",
    "feats_train = features[index[:num_train]]\n",
    "Y_train = Y[index[:num_train]]\n",
    "feats_val = features[index[num_train:]]\n",
    "Y_val = Y[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "X_train = X[index[:num_train]]\n",
    "X_val = X[index[num_train:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimization :**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 2\n",
    "num_layers = 6\n",
    "\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tThe weights and biases of the variational classifier are updated in each iteration using the **NesterovMomentumOptimizer**.\n",
    "\n",
    "•\tThe training and validation accuracy are computed and printed every few iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = NesterovMomentumOptimizer(0.01)\n",
    "batch_size = 5\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(60):\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    feats_train_batch = feats_train[batch_index]\n",
    "    Y_train_batch = Y_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = np.sign(variational_classifier(weights, bias, feats_train.T))\n",
    "    predictions_val = np.sign(variational_classifier(weights, bias, feats_val.T))\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y_train, predictions_train)\n",
    "    acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "    if (it + 1) % 2 == 0:\n",
    "        _cost = cost(weights, bias, features, Y)\n",
    "        print(\n",
    "            f\"Iter: {it + 1:5d} | Cost: {_cost:0.7f} | \"\n",
    "            f\"Acc train: {acc_train:0.7f} | Acc validation: {acc_val:0.7f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Results Visualization**\n",
    "\n",
    "Finally, we visualize the decision boundary learned by the variational classifier.\n",
    "\n",
    "•\tThe decision boundary is visualized, showing how well the classifier can separate the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "cm = plt.cm.RdBu\n",
    "\n",
    "# make data for decision regions\n",
    "xx, yy = np.meshgrid(np.linspace(0.0, 1.5, 30), np.linspace(0.0, 1.5, 30))\n",
    "X_grid = [np.array([x, y]) for x, y in zip(xx.flatten(), yy.flatten())]\n",
    "\n",
    "# preprocess grid points like data inputs above\n",
    "padding = 0.1 * np.ones((len(X_grid), 2))\n",
    "X_grid = np.c_[X_grid, padding]  # pad each input\n",
    "normalization = np.sqrt(np.sum(X_grid**2, -1))\n",
    "X_grid = (X_grid.T / normalization).T  # normalize each input\n",
    "features_grid = np.array([get_angles(x) for x in X_grid])  # angles are new features\n",
    "predictions_grid = variational_classifier(weights, bias, features_grid.T)\n",
    "Z = np.reshape(predictions_grid, xx.shape)\n",
    "\n",
    "# plot decision regions\n",
    "levels = np.arange(-1, 1.1, 0.1)\n",
    "cnt = plt.contourf(xx, yy, Z, levels=levels, cmap=cm, alpha=0.8, extend=\"both\")\n",
    "plt.contour(xx, yy, Z, levels=[0.0], colors=(\"black\",), linestyles=(\"--\",), linewidths=(0.8,))\n",
    "plt.colorbar(cnt, ticks=[-1, 0, 1])\n",
    "\n",
    "# plot data\n",
    "for color, label in zip([\"b\", \"r\"], [1, -1]):\n",
    "    plot_x = X_train[:, 0][Y_train == label]\n",
    "    plot_y = X_train[:, 1][Y_train == label]\n",
    "    plt.scatter(plot_x, plot_y, c=color, marker=\"o\", ec=\"k\", label=f\"class {label} train\")\n",
    "    plot_x = (X_val[:, 0][Y_val == label],)\n",
    "    plot_y = (X_val[:, 1][Y_val == label],)\n",
    "    plt.scatter(plot_x, plot_y, c=color, marker=\"^\", ec=\"k\", label=f\"class {label} validation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "This step-by-step approach allows us to understand how quantum variational classifiers work and how to implement them using PennyLane."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
