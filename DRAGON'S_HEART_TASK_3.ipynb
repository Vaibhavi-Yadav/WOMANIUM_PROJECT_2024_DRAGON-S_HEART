{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ TASK-3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classical Convolution**\n",
    "\n",
    "**Definition :** In the context of Convolutional Neural Networks, Classical Convolution denotes a technique where a small filter or kernel slides or convolves over parts of the input data to extract features. All in all, the procedure entails the sliding of a filter across an input image and the performance of element-wise multiplication and summation.\n",
    "\n",
    "**Operation :** A CNN processes small regions of an image at a time because of its convolutional layer, enabling the model to learn local patterns such as edges and textures. This convolves each region with a kernel to give one output pixel, typically forming a larger feature map.\n",
    "\n",
    "**Feature Extraction :** Further feature extraction or classification is performed by additional layers after processing the resulting feature maps. The ability to understand spatial hierarchies in images is the main strength of CNNs because they stack multiple convolutional layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantum Convolution**\n",
    "\n",
    "**Definition :** Quantum convolution can be defined as the generalization of classical convolution into Quantum Variational Circuits. In quantum convolution local patches from the input data will be embedded in the quantum circuit and after that, quantum operations are applied over there.\n",
    "\n",
    "**Process :**\n",
    "\n",
    "**Circuit Embedding :** A small portion of the input image, e.g., a 2x2 patch of pixels, is physically embedded in the circuit. The parametrized quantum gates represent a mapping from classical data to quantum states.\n",
    "\n",
    "**Quantum Computation :** The unitary transformation application  Quantum computation on the encoded data can be shown to be effectively given by the application.\n",
    "\n",
    "**Measurement :** Read out the quantum circuit in order to end up with classical expectation values associated with the probability of the state measurement which would be extracted quantum features related to the input data.\n",
    "\n",
    "**Output Mapping :** Each expectation value corresponds to a different O pixel channel; thus, the need to perform a classical layer, similar to the convolutional case.\n",
    "\n",
    "**Iterate :** Do this for every patch of the image to obtain a new image-like object that can be further processed.\n",
    "\n",
    "**Benefits :** Quantum circuits can potentially create complex transformations that are computationally expensive or intractable for classical systems. They have the ability to capture intricate data patterns through entanglement and superposition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. General Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we set up the Python environment and all the necessary libraries to conduct the experiment.\n",
    "\n",
    "**A) PennyLane :** PennyLane is a quantum machine learning library by which one can easily do quantum or classical computation. We are using it for quantum circuit simulations.\n",
    "\n",
    "**B) TensorFlow :** A popular machine learning library. We'll be using it here to build the classical components of our model and to train the whole network.\n",
    "\n",
    "**C) Matplotlib :** An extensive plotting library. We will use it here to display our dataset and some plots from the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Hyper-Parameters :**\n",
    "\n",
    "**A) n_epochs :** The number of epochs that we would like to train our classical model. \n",
    "\n",
    "**B) n_layers :** Number of the random layers used in our quantum circuit.\n",
    "\n",
    "**C) n_train :** Number of samples for training.\n",
    "\n",
    "**D) n_test :** Number of samples for testing.\n",
    "\n",
    "**E) SAVE_PATH :** Save path of preprocessing the images\n",
    "\n",
    "**F) PREPROCESS :** Boolean flag to decide for quantum preprocessing or not\n",
    "\n",
    "**G) Random Seeds :** Fixing the seeds to make results reproducible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30   # Number of optimization epochs\n",
    "n_layers = 1    # Number of random layers\n",
    "n_train = 50    # Size of the train dataset\n",
    "n_test = 30     # Size of the test dataset\n",
    "\n",
    "SAVE_PATH = \"Copy path of new folder in which mnist.npz is located\"  # Data saving folder\n",
    "PREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\n",
    "np.random.seed(0)           # Seed for NumPy random number generator\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Loading MNIST Dataset :**\n",
    "\n",
    "**A) Description :** MNIST is a large database that comprises 28 × 28 gray images of handwritten digits from 0 to 9. It is usually use to train and test image processing systems.\n",
    "\n",
    "**B) Data Preparation :** In this example, we are going to use only a subsection of the MNIST dataset. We are doing this to reduce the computation time taken to complete of our code. We also reduce the number of samples for both training and testing.\n",
    "\n",
    "**C) Normalization :** This normalizes the pixel values for the images to lie within the range of [0, 1]. This step is crucial for the implementation of the neural network.\n",
    "\n",
    "**D) Adding a channel :** It adds an extra dimension to represent the convolution channels to each of the images because the convolutional operation requires the 3D space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "# Reduce dataset size\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = test_labels[:n_test]\n",
    "\n",
    "# Normalize pixel values within 0 and 1\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    "\n",
    "# Add extra dimension for convolution channels\n",
    "train_images = np.array(train_images[..., tf.newaxis], requires_grad=False)\n",
    "test_images = np.array(test_images[..., tf.newaxis], requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Quantum Circuit as a Convolution Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are defining the quantum circuit which shall play the role of convolution kernel. The quantum circuit is called for small image patches of the input image and the expectation values thus returned are used as the feature input for further layers.\n",
    "\n",
    "**3.1 Device Initialization :**\n",
    "\n",
    "**A) Device :** We use PennyLane's default.qubit simulator. This is a quantum device simulator with a 4-qubit quantum device.\n",
    "\n",
    "**B) Random Parameters :** Parameters for the quantum circuit are initialized with random values. It is these parameters which are responsible for effecting the dynamics of the quantum gates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Quantum Circuit Definition**\n",
    "\n",
    "**A) Encoding :** The quantum processing circuit encodes the 2x2 pixel region from the input image using parameterised rotation gates. In particular, we use the RYRY gate with angles scaled in increments of ππ angles.\n",
    "\n",
    "**B) Random Layers :** A set of random quantum layers are appended, sampled from the distribution defined by the variational parameters at initialization. This introduces the randomness and complexity in the kernel.\n",
    "\n",
    "**C) Measurement :** The expectation values of the Pauli-Z operator for each qubit is measured. These measurements are the quantum features taken from the input region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "# Random circuit parameters\n",
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(phi):\n",
    "    # Encoding of 4 classical input values\n",
    "    for j in range(4):\n",
    "        qml.RY(np.pi * phi[j], wires=j)\n",
    "\n",
    "    # Random quantum circuit\n",
    "    RandomLayers(rand_params, wires=list(range(4)))\n",
    "\n",
    "    # Measurement producing 4 classical output values\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Convolution Scheme**\n",
    "\n",
    "This procedure defines the process of applying quantum convolution to the input image.\n",
    "\n",
    "**Steps :**\n",
    "\n",
    "**A) Input Division :** The input image is divided into non-overlapping 2x2 pixel units.\n",
    "\n",
    "**B) Quantum Procedure :** The each pixel unit undergo the quantum procedure defined above so that the expectation values are returned.\n",
    "\n",
    "**C) Channel Assignation :** Expectation values are assigned to the four channels of the single output pixel.This is a convolution of 2x2 stride 2.\n",
    "\n",
    "**D) Output Builder :** The whole image goes through this process to produce a downsampled output image of multiple channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanv(image):\n",
    "    \"\"\"Convolves the input image with many applications of the same quantum circuit.\"\"\"\n",
    "    out = np.zeros((14, 14, 4))\n",
    "\n",
    "    # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
    "    for j in range(0, 28, 2):\n",
    "        for k in range(0, 28, 2):\n",
    "            # Process a squared 2x2 region of the image with a quantum circuit\n",
    "            q_results = circuit(\n",
    "                [\n",
    "                    image[j, k, 0],\n",
    "                    image[j, k + 1, 0],\n",
    "                    image[j + 1, k, 0],\n",
    "                    image[j + 1, k + 1, 0]\n",
    "                ]\n",
    "            )\n",
    "            # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
    "            for c in range(4):\n",
    "                out[j // 2, k // 2, c] = q_results[c]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4 Quantum pre-processing of the dataset**\n",
    "\n",
    "Since quantum convolution is actually a fixed, non-trainable layer, we apply it in the pre-processing to the entire dataset. Thus, during the actual training, it maintains reasonable computational overhead.\n",
    "\n",
    "**A) Train Images :** The quantum convolution function is applied to each image of the training.\n",
    "Set and storing the outputs.\n",
    "\n",
    "**B) Test Images :** Process of test set\n",
    "\n",
    "**C) Output Saving :** Output is saved, so it can be used in subsequent operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS == True:\n",
    "    q_train_images = []\n",
    "    print(\"Quantum pre-processing of train images:\")\n",
    "    for idx, img in enumerate(train_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_train), end=\"\\r\")\n",
    "        q_train_images.append(quanv(img))\n",
    "    q_train_images = np.asarray(q_train_images)\n",
    "\n",
    "    q_test_images = []\n",
    "    print(\"\\nQuantum pre-processing of test images:\")\n",
    "    for idx, img in enumerate(test_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_test), end=\"\\r\")\n",
    "        q_test_images.append(quanv(img))\n",
    "    q_test_images = np.asarray(q_test_images)\n",
    "\n",
    "    # Save pre-processed images\n",
    "    np.save(SAVE_PATH + \"q_train_images.npy\", q_train_images)\n",
    "    np.save(SAVE_PATH + \"q_test_images.npy\", q_test_images)\n",
    "\n",
    "\n",
    "# Load pre-processed images\n",
    "q_train_images = np.load(SAVE_PATH + \"q_train_images.npy\")\n",
    "q_test_images = np.load(SAVE_PATH + \"q_test_images.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5 Quantum Convolution Effect Visualization**\n",
    "\n",
    "In this quantum convolution, we visualize the effect of the Quantum Convolution on the input images.\n",
    "\n",
    "**Visualization:**\n",
    "\n",
    "**A) Input Image :** Sample input images from the training dataset is taken.\n",
    "\n",
    "**B) Quantum Features :** For each input image, we draw the output of each channel when that input is processed into the Quantum conv layer. Each channel illustrates a different quantum feature which is learned from the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4\n",
    "n_channels = 4\n",
    "fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "for k in range(n_samples):\n",
    "    axes[0, 0].set_ylabel(\"Input\")\n",
    "    if k != 0:\n",
    "        axes[0, k].yaxis.set_visible(False)\n",
    "    axes[0, k].imshow(train_images[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    # Plot all output channels\n",
    "    for c in range(n_channels):\n",
    "        axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
    "        if k != 0:\n",
    "            axes[c, k].yaxis.set_visible(False)\n",
    "        axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hybrid Quantum-Classical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a simple classical neural network which we will train on the quantum-processed images. This hybrid approach combines quantum feature extraction with classical training.\n",
    "\n",
    "**4.1 Model Definiton :**\n",
    "\n",
    "**A) Input Layer :** No input layer\n",
    "\n",
    "**B) Dense Layer :** 10 neurons, Softmax activation. The dense layer or classification layer.\n",
    "\n",
    "**C) Compile :** The model is then compiled with the Adam optimizer and sparse categorical cross-entropy loss, as this is a multi-class classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Training :**\n",
    "\n",
    "We first initialize an instance of the model, then we train and validate it with the dataset that has been already pre-processed by a quantum convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your model (unindented)\n",
    "q_model = MyModel()  \n",
    "\n",
    "q_history = q_model.fit(\n",
    "    q_train_images,\n",
    "    train_labels,\n",
    "    validation_data=(q_test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare the results achievable with and without the quantum convolution layer, we initialize also a “classical” instance of the model that will be directly trained and validated with the raw MNIST images (i.e., without quantum pre-processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model = MyModel()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 Results**\n",
    "\n",
    "We can finally plot the test accuracy and the test loss with respect to the number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "ax1.plot(q_history.history[\"val_accuracy\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax1.plot(c_history.history[\"val_accuracy\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(q_history.history[\"val_loss\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax2.plot(c_history.history[\"val_loss\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_ylim(top=2.5)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
